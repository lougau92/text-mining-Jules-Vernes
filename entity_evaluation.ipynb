{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/louis/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/louis/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk import pos_tag, word_tokenize, sent_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "\n",
    "def read_file(file_name):\n",
    "    with open(file_name) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "path = './data/test_book'\n",
    "\n",
    "text = read_file(path)\n",
    "\n",
    "text = [x.strip() for x in text]\n",
    "text = ' '.join(text)\n",
    "text = re.sub(' +', lambda match: ' '+'Q' * (len(match.group(0))-1), text)                                             \n",
    "\n",
    "\n",
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "# tokenizer._realign_boundaries = True   \n",
    "\n",
    "sentences = tokenizer.tokenize(text)\n",
    "for sent in sentences:    sent =  re.sub('Q+', ' ', sent)   \n",
    "\n",
    "words = nltk.tokenize.word_tokenize(text)\n",
    "token_sentences = [word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "pos_sentences = [nltk.pos_tag(sent) for sent in token_sentences]\n",
    "chunked_sentences = nltk.ne_chunk_sents(pos_sentences, binary=True)\n",
    "from collections import defaultdict\n",
    "\n",
    "# Create the defaultdict: ner_categories\n",
    "ner_categories = defaultdict(int)\n",
    "chunked_sentences = nltk.ne_chunk_sents(pos_sentences, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON V 9 V\n",
      "PERSON Ned Land 425 Ned Land\n",
      "PERSON Farragut 546 Farragut\n",
      "PERSON Ned Land 575 Ned Land\n",
      "PERSON Ned Land 879 Ned Land\n",
      "PERSON Cape Vierges 1082 Cape Vierges\n",
      "PERSON Cape Horn 1166 Cape Horn\n",
      "PERSON Cape Horn 1657 Cape Horn\n",
      "PERSON Capricorn 3576 Capricorn\n",
      "PERSON Farragut 3815 Farragut\n",
      "LOCATION Northern Pacific 4931 Northern Pacific\n",
      "PERSON Captain Farragut 5989 Captain Farragut\n",
      "PERSON Columbus 6010 Columbus\n",
      "PERSON Conseil 8323 Conseil\n",
      "PERSON Conseil 8323 Conseil\n",
      "PERSON Conseil 8844 Conseil\n",
      "PERSON Plantes 9011 Plantes\n",
      "PERSON Conseil 9206 Conseil\n",
      "PERSON Q 9617 Q\n",
      "PERSON Ned 9764 Ned\n",
      "PERSON Ned Land 10797 Ned Land\n",
      "PERSON Conseil 10829 Conseil\n",
      "PERSON Conseil 11045 Conseil\n",
      "PERSON Ned Land 11096 Ned Land\n",
      "PERSON Master Land 11152 Master Land\n",
      "PERSON Ned Land 11942 Ned Land\n",
      "PERSON Ned 11991 Ned\n",
      "PERSON Conseil 12002 Conseil\n",
      "PERSON Conseil 12286 Conseil\n",
      "PERSON Conseil 13587 Conseil\n",
      "PERSON Conseil 13875 Conseil\n",
      "PERSON Ned Land 13902 Ned Land\n",
      "PERSON Conseil 14701 Conseil\n",
      "PERSON Ned Land 14751 Ned Land\n",
      "PERSON Conseil 14787 Conseil\n",
      "PERSON Ned Land 15076 Ned Land\n",
      "PERSON Ned 15778 Ned\n",
      "PERSON Ned Land 16109 Ned Land\n",
      "PERSON Conseil 16791 Conseil\n",
      "PERSON Ned 16882 Ned\n",
      "PERSON Ned 16882 Ned\n",
      "PERSON Hunger 18885 Hunger\n",
      "PERSON Conseil 18987 Conseil\n",
      "PERSON Ned 19252 Ned\n",
      "PERSON Ned 19499 Ned\n",
      "PERSON Ned 19697 Ned\n",
      "PERSON Conseil 19777 Conseil\n",
      "PERSON Conseil 20184 Conseil\n",
      "PERSON Conseil 20330 Conseil\n",
      "PERSON Conseil 20560 Conseil\n",
      "PERSON Ned 20736 Ned\n",
      "PERSON Jove 20790 Jove\n",
      "PERSON Conseil 20931 Conseil\n",
      "PERSON Ned Land 21942 Ned Land\n",
      "PERSON Ned 22128 Ned\n",
      "PERSON Ned 22423 Ned\n",
      "PERSON Ned Land 22706 Ned Land\n",
      "PERSON Happy Ned 23421 Happy Ned\n",
      "PERSON Ned 23771 Ned\n",
      "PERSON Conseil 24348 Conseil\n",
      "PERSON Ned Land 24391 Ned Land\n",
      "PERSON Master 25033 Master\n",
      "PERSON Master Ned 25033 Master Ned\n",
      "PERSON Captain Nemo 25224 Captain Nemo\n",
      "PERSON Ned 25276 Ned\n",
      "PERSON Conseil 25329 Conseil\n",
      "PERSON Conseil 26280 Conseil\n",
      "PERSON Conseil 27367 Conseil\n",
      "PERSON Good 27428 Good\n",
      "PERSON Nemo 28929 Nemo\n",
      "PERSON Captain Nemo 31367 Captain Nemo\n",
      "PERSON Captain Nemo 32754 Captain Nemo\n",
      "PERSON Captain Nemo 34800 Captain Nemo\n"
     ]
    }
   ],
   "source": [
    "relevant_tags= ['PERSON', 'LOCATION']\n",
    "predicted_labels =[]\n",
    "\n",
    "from nltk.translate.ribes_score import position_of_ngram\n",
    "\n",
    "\n",
    "chunked_sentences = nltk.ne_chunk_sents(pos_sentences, binary=False)\n",
    "\n",
    "\n",
    "index = 0\n",
    "# Create the nested for loop\n",
    "for i,chuncked_sent in enumerate(chunked_sentences):\n",
    "    raw_sent = sentences[i]\n",
    "    for chunk in chuncked_sent:\n",
    "        if hasattr(chunk, 'label'):\n",
    "            if chunk.label() in relevant_tags:\n",
    "                class_ = chunk.label()\n",
    "                value = ' '.join(c[0] for c in chunk.leaves())\n",
    "                pos = raw_sent.find(value)\n",
    "                print(class_, value,  index+pos, text[index+pos:index+pos+len(value)])\n",
    "                predicted_labels.append((class_, index+pos, index+pos+len(value)))\n",
    "                if index == None:          \n",
    "                    print(raw_sent)\n",
    "                    print(class_, value, index)\n",
    "\n",
    "    index += len(raw_sent)+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON Ned Land 13902 13910\n",
      "PERSON Conseil 12388 12395\n",
      "LOCATION the\n",
      "tropic of Cancer 4156 4176\n",
      "LOCATION Cape Horn 1166 1175\n",
      "PERSON Commander Farragut 7220 7238\n",
      "PERSON the Canadian 20807 20819\n",
      "PERSON the\n",
      "captain of the _Monroe_ 383 410\n",
      "PERSON Conseil 25329 25336\n",
      "PERSON the Canadian 23001 23013\n",
      "PERSON Hunger 18885 18891\n",
      "PERSON Captain Nemo 27321 27333\n",
      "PERSON Ned Land 15778 15786\n",
      "PERSON Ned Land 9598 9606\n",
      "PERSON Conseil 18987 18994\n",
      "PERSON master 14031 14037\n",
      "PERSON Ned Land 11096 11104\n",
      "PERSON _Nautilus_ 10766 10776\n",
      "PERSON _Nautilus_ 33826 33836\n",
      "PERSON Master 11474 11480\n",
      "LOCATION the tropic of Capricorn 3562 3585\n",
      "PERSON Captain 26472 26479\n",
      "PERSON Captain 25346 25353\n",
      "LOCATION Island of Crespo 34958 34974\n",
      "PERSON Ned Land 14751 14759\n",
      "PERSON Ned 25276 25279\n",
      "PERSON the Canadian 14654 14666\n",
      "PERSON _Nautilus_ 24317 24327\n",
      "PERSON Commander Farragut 536 554\n",
      "PERSON M. Aronnax 19552 19562\n",
      "LOCATION France 8783 8789\n",
      "LOCATION the Sandwich Islands 4126 4146\n",
      "PERSON Captain Farragut 5436 5452\n",
      "LOCATION the island of Gilboa 12928 12948\n",
      "PERSON Conseil 9206 9213\n",
      "PERSON Conseil 13587 13594\n",
      "PERSON Conseil 13875 13882\n",
      "PERSON _Abraham Lincoln_ 5551 5568\n",
      "PERSON Conseil 11500 11507\n",
      "PERSON Conseil 20560 20567\n",
      "PERSON Conseil 14787 14794\n",
      "LOCATION the China Seas 4191 4205\n",
      "PERSON Captain\n",
      "Nemo 28921 28933\n",
      "PERSON bari-outang 22025 22036\n",
      "PERSON Ned\n",
      "Land 21942 21950\n",
      "PERSON Conseil 2960 2967\n",
      "PERSON The Malays 18189 18199\n",
      "LOCATION Papuan islands 17702 17716\n",
      "PERSON Ned Land 15076 15084\n",
      "PERSON Conseil 19777 19784\n",
      "PERSON Conseil 8323 8330\n",
      "PERSON The â€œbari-outang 23890 23906\n",
      "PERSON Conseil 10829 10836\n",
      "PERSON Captain Nemo 9907 9919\n",
      "PERSON Conseil 8449 8456\n",
      "PERSON Conseil 31242 31249\n",
      "PERSON the Americans 32893 32906\n",
      "PERSON _Abraham\n",
      "Lincoln_ 1455 1472\n",
      "PERSON Ned 24770 24773\n",
      "PERSON Master 25033 25039\n",
      "PERSON Ned 13372 13375\n",
      "PERSON _Nautilus_ 9946 9956\n",
      "PERSON Ned Land 23771 23779\n",
      "PERSON Professor 27177 27186\n",
      "PERSON Ned Land 22706 22714\n",
      "PERSON Hercules 26229 26237\n",
      "PERSON Ned 19697 19700\n",
      "PERSON Master 20342 20348\n",
      "PERSON the Chinese 18248 18259\n",
      "LOCATION Marquesas 4112 4121\n",
      "PERSON _Nautilus_ 27192 27202\n",
      "PERSON _Nautilus_ 28689 28699\n",
      "PERSON _Nautilus_ 15397 15407\n",
      "PERSON Ned 12106 12109\n",
      "PERSON the Canadian 12032 12044\n",
      "PERSON Conseil 24348 24355\n",
      "PERSON Ned Land 11942 11950\n",
      "PERSON the Canadian 10866 10878\n",
      "PERSON _Abraham Lincoln_ 6167 6184\n",
      "PERSON Ned 11991 11994\n",
      "PERSON Conseil 28993 29000\n",
      "PERSON Ned 16882 16885\n",
      "LOCATION Papua 21124 21129\n",
      "PERSON M. Aronnax 24943 24953\n",
      "PERSON _Nautilus_ 26543 26553\n",
      "PERSON _Abraham Lincoln_ 4882 4899\n",
      "PERSON Captain Nemo 26179 26191\n",
      "PERSON Conseil 9089 9096\n",
      "PERSON Ned Land 425 433\n",
      "PERSON Ned 16942 16945\n",
      "LOCATION Straits of\n",
      "Magellan 1050 1069\n",
      "PERSON Captain Farragut 5989 6005\n",
      "LOCATION the Arrow 17688 17697\n",
      "PERSON Conseil 27367 27374\n",
      "PERSON _Abraham Lincoln_ 6938 6955\n",
      "PERSON Conseil 11691 11698\n",
      "LOCATION Cape Horn 1657 1666\n",
      "PERSON _Abraham Lincoln_ 3110 3127\n",
      "PERSON the Canadian 27446 27458\n",
      "PERSON Conseil 20330 20337\n",
      "PERSON Ned 23427 23430\n",
      "PERSON Ned 20736 20739\n",
      "PERSON the Malays 14986 14996\n",
      "LOCATION Malaya 13020 13026\n",
      "PERSON Captain Nemo 34800 34812\n",
      "PERSON Conseil 25243 25250\n",
      "PERSON Conseil 9470 9477\n",
      "LOCATION Australia 3397 3406\n",
      "PERSON Conseil 8844 8851\n",
      "PERSON Master Ned 25206 25216\n",
      "PERSON Ned Land 9764 9772\n",
      "PERSON Ned Land 13048 13056\n",
      "PERSON Master 13269 13275\n",
      "PERSON Conseil 16791 16798\n",
      "PERSON _Abraham Lincoln_ 459 476\n",
      "PERSON the Canadian 21885 21897\n",
      "PERSON Ned 14206 14209\n",
      "PERSON Captain Nemo 27012 27024\n",
      "PERSON Conseil 14701 14708\n",
      "PERSON _Nautilus_ 30305 30315\n",
      "PERSON Master Land 11152 11163\n",
      "PERSON _Nautilus_ 24594 24604\n",
      "PERSON the Canadian 13470 13482\n",
      "PERSON the Canadian 16083 16095\n",
      "PERSON The hunters 18905 18916\n",
      "PERSON Captain Nemo 31367 31379\n",
      "PERSON the Canadian 11727 11739\n",
      "LOCATION the Island of Crespo 24790 24810\n",
      "PERSON Conseil 8142 8149\n",
      "PERSON Ned Land 183 191\n",
      "PERSON Conseil 8630 8637\n",
      "PERSON Conseil 16927 16934\n",
      "PERSON Ned Land 575 583\n",
      "PERSON _Nautilus!_ 22828 22839\n",
      "PERSON master 14191 14197\n",
      "PERSON _Nautilus_ 23692 23702\n",
      "PERSON Conseil 7764 7771\n",
      "PERSON Ned Land 879 887\n",
      "PERSON _Nautilus_ 11459 11469\n",
      "PERSON Ned Land 16109 16117\n",
      "PERSON Ned Land 10797 10805\n",
      "LOCATION south-east coast of America 955 982\n",
      "PERSON _Abraham Lincoln_ 44 61\n",
      "PERSON Ned Land 24676 24684\n",
      "LOCATION Cape Vierges 1082 1094\n",
      "PERSON Conseil 11045 11052\n",
      "PERSON Jove 20790 20794\n",
      "PERSON Conseil 22431 22438\n",
      "PERSON Captain Nemo 25224 25236\n",
      "PERSON Ned 22423 22426\n",
      "PERSON Ned 19252 19255\n",
      "PERSON Commander\n",
      "Farragut 3805 3823\n",
      "PERSON Conseil 20931 20938\n",
      "PERSON Ned 19499 19502\n",
      "PERSON Ned Land 24391 24399\n",
      "PERSON Conseil 20184 20191\n",
      "PERSON Ned 12101 12104\n",
      "PERSON Ned Land 22128 22136\n",
      "PERSON Conseil 26280 26287\n",
      "PERSON Conseil 12286 12293\n",
      "PERSON The\n",
      "Canadian 22217 22229\n",
      "PERSON Commander Farragut 1100 1118\n"
     ]
    }
   ],
   "source": [
    "# read the annotated file\n",
    "path = './data/job-1_annotations.json'\n",
    "import json\n",
    "\n",
    "def read_json(file_name):\n",
    "    with open(file_name) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "file = read_json(path)\n",
    "\n",
    "# for key in file['examples'][0].keys():\n",
    "#     if key == 'content':\n",
    "#         continue\n",
    "#     print(key)\n",
    "#     print(file['examples'][0][key])\n",
    "#     print('\\n')\n",
    "\n",
    "annotations = file['examples'][0]['annotations']\n",
    "# for annotation in annotations:\n",
    "#     print(annotation['tag'])\n",
    "#     print(annotation['value'])\n",
    "#     print(annotation['start'])\n",
    "#     print(annotation['end'])\n",
    "#     print('\\n')\n",
    "\n",
    "# extract the true labels\n",
    "true_labels = []\n",
    "for annotation in annotations:\n",
    "    true_labels.append((annotation['tag'], annotation['start'], annotation['end']))\n",
    "    print(annotation['tag'], annotation['value'], annotation['start'], annotation['end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.7123287671232876\n",
      "recall:  0.32298136645962733\n",
      "F1 score:  0.4444444444444445\n"
     ]
    }
   ],
   "source": [
    "# calculate the precision and recall\n",
    "\n",
    "True_positives = 0\n",
    "False_positives = 0\n",
    "False_negatives = 0\n",
    "for label in predicted_labels:\n",
    "    if label in true_labels:\n",
    "        True_positives += 1\n",
    "    else:\n",
    "        False_positives += 1\n",
    "    \n",
    "False_negatives = len(true_labels) - True_positives\n",
    "\n",
    "precision = True_positives / (True_positives + False_positives)\n",
    "recall = True_positives / (True_positives + False_negatives)\n",
    "\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('F1 score: ', 2 * precision * recall / (precision + recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
